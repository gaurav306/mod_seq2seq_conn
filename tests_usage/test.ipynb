{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 class not used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.test1 at 0x26640b976d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test1():\n",
    "    def __init__(self):\n",
    "        x = 1\n",
    "        if x==1:\n",
    "            print('test1 class not used')\n",
    "            return\n",
    "        print('test1')\n",
    "        self.okk()\n",
    "    \n",
    "    def okk(self):\n",
    "        print('okk')\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_1_inputs\n",
      "decoder_1_inputs\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(f\"decoder_{i}_inputs\")\n",
    "print('decoder_%s_inputs' % str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.dense_output = layers.Dense(original_dim, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_dim,\n",
    "        intermediate_dim=64,\n",
    "        latent_dim=32,\n",
    "        name=\"autoencoder\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "        )\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = 0.3191\n",
      "step 100: mean loss = 0.1256\n",
      "step 200: mean loss = 0.0991\n",
      "step 300: mean loss = 0.0892\n",
      "step 400: mean loss = 0.0842\n",
      "step 500: mean loss = 0.0809\n",
      "step 600: mean loss = 0.0787\n",
      "step 700: mean loss = 0.0771\n",
      "step 800: mean loss = 0.0760\n",
      "step 900: mean loss = 0.0749\n",
      "Start of epoch 1\n",
      "step 0: mean loss = 0.0747\n",
      "step 100: mean loss = 0.0740\n",
      "step 200: mean loss = 0.0735\n",
      "step 300: mean loss = 0.0730\n",
      "step 400: mean loss = 0.0727\n",
      "step 500: mean loss = 0.0723\n",
      "step 600: mean loss = 0.0720\n",
      "step 700: mean loss = 0.0717\n",
      "step 800: mean loss = 0.0715\n",
      "step 900: mean loss = 0.0712\n"
     ]
    }
   ],
   "source": [
    "# Iterate over epochs.\n",
    "for epoch in range(2):\n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed = vae(x_batch_train)\n",
    "            # Compute reconstruction loss\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(vae.losses)  # Add KLD regularization loss\n",
    "\n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  54400     \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  53072     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,472\n",
      "Trainable params: 107,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size):\n",
    "    #super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    super().__init__()\n",
    "    \n",
    "\n",
    "    self.conv2a = tf.keras.layers.Dense(kernel_size, activation='relu')\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Dense(kernel_size, activation='relu')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Dense(kernel_size, activation='relu')\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_identity_block\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_91 (Dense)            multiple                  4         \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  multiple                 4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_92 (Dense)            multiple                  2         \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  multiple                 4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_93 (Dense)            multiple                  2         \n",
      "                                                                 \n",
      " batch_normalization_83 (Bat  multiple                 4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 14\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=(96,12), name='encoder_past_inputs')\n",
    "\n",
    "model_output = tf.keras.layers.Dense(12, activation='sigmoid', name='model_output')(encoder_inputs)\n",
    "\n",
    "for i in range(10):    \n",
    "    csmodel = ResnetIdentityBlock(12)\n",
    "    model_output1 = csmodel(model_output)\n",
    "    model_output = model_output1\n",
    "\n",
    "\n",
    "model_output3 = tf.keras.layers.Dense(12, activation='sigmoid', name='model_output3')(model_output1)\n",
    "\n",
    "model = tf.keras.Model(inputs=encoder_inputs, outputs=model_output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_past_inputs (InputL  [(None, 96, 12)]         0         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " model_output (Dense)        (None, 96, 12)            156       \n",
      "                                                                 \n",
      " resnet_identity_block_1 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_2 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_3 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_4 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_5 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_6 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_7 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_8 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_9 (Re  (None, 96, 12)           612       \n",
      " snetIdentityBlock)                                              \n",
      "                                                                 \n",
      " resnet_identity_block_10 (R  (None, 96, 12)           612       \n",
      " esnetIdentityBlock)                                             \n",
      "                                                                 \n",
      " model_output3 (Dense)       (None, 96, 12)            156       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,432\n",
      "Trainable params: 5,712\n",
      "Non-trainable params: 720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdwork1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
