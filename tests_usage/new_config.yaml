# ALL BASIC SETTINGS INDEPENDENT OF MODEL ARCHITECTURE
if_model_image: 1
if_model_summary: 0
if_seed: 0
seed: 500

model_type_prob: prob
loss_prob: nonparametric
loss: mean_squared_error
quantiles: [0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99]
metrics: [mape, acc]
optimizer: Adam
Adam:
  lr: 0.001
  b1: 0.9
  b2: 0.999
  epsi: 1.0e-08
SGD:
  lr: 0.001
  momentum: 0.9
save_models_dir: saved_models/

batch_size: 32

n_past: 672
n_future: 96
known_past_features: 31
unknown_future_features: 1
known_future_features: 15
control_future_cells: 1

all_layers_neurons: 128
all_layers_dropout: 0.4

# ENCODER SETTINGS
encoder:
  TCN_encoder_input:
    IF_TCN_encoder_input: 1
    kernel_size_encoder_input: 3
    nb_stacks_encoder_input: 2
    dilations_encoder_input: [1, 2, 4, 8, 16, 32]
  
  RNN_block_encoder_input:
    # settings for RNN block outside the block class
    IF_RNN_encoder_input: 1
    IF_NONE_GLUADDNORM_ADDNORM_block_encoder_input: 1         #0: None, 1: GLUADDNORM, 3: ADDNORM
    IF_GRN_block_encoder_input: 1                             #0: no GRN, 1: GRN
    # settings for RNN units inside the blocks
    rnn_depth_encoder_input: 3
    rnn_type_encoder_input: GRU                               # GRU, LSTM, SimpleRNN
    IF_birectionalRNN_encoder_input: 1                        # 0: no bidirectional, 1: bidirectional
    IF_NONE_GLUADDNORM_ADDNORM_deep_encoder_input: 1          #0: None, 1: GLUADDNORM, 3: ADDNORM
  
  IF_POS_ENCODE_encoder_input: 1

  self_MHA_block_encoder:
    # settings for self MHA block outside the block class
    MHA_depth_encoder: 3
    # settings for self MHA units inside the blocks
    IF_MHA_encoder: 1
    MHA_head_encoder: 8
    IF_NONE_GLUADDNORM_ADDNORM_deep_encoder: 1                #0: None, 1: GLUADDNORM, 3: ADDNORM

# DECODER SETTINGS
decoder:
  TCN_decoder_input:
    IF_TCN_decoder_input: 1
    kernel_size_decoder_input: 3
    nb_stacks_decoder_input: 2
    dilations_decoder_input: [1, 2, 4, 8, 16, 32]

  RNN_block_decoder_input:
    # settings for RNN block outside the block class
    IF_RNN_decoder_input: 1
    IF_NONE_GLUADDNORM_ADDNORM_block_decoder_input: 1         #0: None, 1: GLUADDNORM, 3: ADDNORM
    IF_GRN_block_decoder_input: 0                             #0: no GRN, 1: GRN
    # settings for RNN units inside the blocks
    rnn_depth_decoder_input: 3
    rnn_type_decoder_input: GRU                               # GRU, LSTM, SimpleRNN
    IF_birectionalRNN_decoder_input: 1                        # 0: no bidirectional, 1: bidirectional
    IF_NONE_GLUADDNORM_ADDNORM_deep_decoder_input: 1          #0: None, 1: GLUADDNORM, 3: ADDNORM
  
  IF_POS_ENCODE_decoder_input: 1

  IF_DECODER_MHA: 1
  MHA_depth_decoder: 3

  self_MHA_block_decoder:
    # settings for self MHA units inside the blocks
    IF_MHA_decoder: 1
    MHA_head_decoder: 8
    IF_NONE_GLUADDNORM_ADDNORM_deep_decoder: 1                 #0: None, 1: GLUADDNORM, 3: ADDNORM

  cross_MHA_block_decoder:
    # settings for cross MHA units inside the blocks
    IF_MHA_decoder: 1
    MHA_head_decoder: 8
    IF_NONE_GLUADDNORM_ADDNORM_deep_decoder: 1                 #0: None, 1: GLUADDNORM, 3: ADDNORM

  TCN_decoder_output:
    IF_TCN_decoder_output: 1
    kernel_size_decoder_output: 3
    nb_stacks_decoder_output: 2
    dilations_decoder_output: [1, 2, 4, 8, 16, 32]

  RNN_block_decoder_output:
    # settings for RNN block outside the block class
    IF_RNN_decoder_output: 1
    IF_NONE_GLUADDNORM_ADDNORM_block_decoder_output: 0          #0: None, 1: GLUADDNORM, 3: ADDNORM
    IF_GRN_block_decoder_output: 1                              #0: no GRN, 1: GRN
    # settings for RNN units inside the blocks
    rnn_depth_decoder_output: 3
    rnn_type_decoder_output: GRU                                # GRU, LSTM, SimpleRNN
    IF_birectionalRNN_decoder_output: 1                         # 0: no bidirectional, 1: bidirectional
    IF_NONE_GLUADDNORM_ADDNORM_deep_decoder_output: 1           #0: None, 1: GLUADDNORM, 3: ADDNORM

  MERGE_STATES_METHOD: 4
  #-----about merging states from Encoder_states(A) and Decoder_input_states(B) for Decoder_output init_states
  # there are 8 options:
  # 1: None
  # 2: A - Dense layer
  # 3: B - Dense layer
  # 4: A+B - Concat -> Dense layer -------------------> this is the best one
  # 5: A+B - Add -> Dense layer
  # 6: A+B - Add_Norm -> Dense layer
  # 7: A+B - Add
  # 8: A+B - Add_Norm

  IFATTENTION: 1                                                # 0 is no attention, 1 attention
  attn_type: 2                                                  # 1 is Luong attention, 2 is Bahdanau attention ----> preffered is 2
